{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should I mention in this answer?\n",
    "\n",
    "- All parameters are coupled\n",
    "- We need to pick a representation of markov networks. We will consider MNs with *positive* factors rather than nonnegative.\n",
    "- With complete data, what defines parameters that are our MLE?\n",
    "- What is the gradient?\n",
    "- What happens with incomplete data?\n",
    "\n",
    "\n",
    "What is the structure\n",
    "- Intro (I don't know what I call out yet)\n",
    "- Refresher but only on MNs\n",
    "- Introduce the form of the MNs: Imagine any positive factors. We can recreate them XYZ way with indicator features. This allows us to bring out the parameters as coefficients that can be any real number.\n",
    "- What defines the MLE?\n",
    "- What is the gradient? (Should I include this?)\n",
    "- WHat happens with missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are the parameters of a Markov Network Learned?\n",
    "\n",
    "INTRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher\n",
    "\n",
    "(Copy this from other online answers)\n",
    "\n",
    "(Gah! We have an issue with overloading $m$. It's both the number of factors and the number of data points)\n",
    "\n",
    "In the first answer [link], we discovered why PGMs are useful tools for representing complex system. We defined a complex system as a set of $n$ random variables (which we call $\\mathcal{X}$) with a relationship we'd like to understand. We take it that there exists some true but unknown joint distribution, $P$, which govern these RVs. We take it that a 'good understanding' means we can answer two types of questions regarding this $P$:\n",
    "\n",
    "1. **Probability Queries**: Compute the probabilities $P(\\mathbf{Y}|\\mathbf{e})$. What is the distribution of the RV's of $\\mathbf{Y}$ given we have some observation ($\\mathbf{e}$) of the RVs of $\\mathbf{E}$?\n",
    "2. **MAP Queries**: Determine $\\textrm{argmax}_\\mathbf{Y}P(\\mathbf{Y}|\\mathbf{e})$. That is, determine the most likely values of some RVs given an assignment of other RVs.\n",
    "\n",
    "(Where $\\mathbf{E}$ and $\\mathbf{Y}$ are two arbitrary subsets of $\\mathcal{X}$. If this notation is unfamiliar, see the 'Notation Guide' section from the first answer [link]).\n",
    "\n",
    "The idea behind PGMs is to estimate $P$ using two things:\n",
    "\n",
    "1. A graph: a set of nodes, each of which represents an RV from $\\mathcal{X}$, and a set of edges between these nodes.\n",
    "2. Parameters: objects that, when paired with a graph and a certain rule, allow us to calculate probabilities of assignments of $\\mathcal{X}$.\n",
    "\n",
    "A **Markov Network**'s graph, denoted as $\\mathcal{H}$, is different in that it's edges are *undirected* and we may have cycles. The parameters are a size $m$ set of *functions* (called ‘factors’) which map assignments of $m$ subsets of $\\mathcal{X}$ to nonnegative numbers. Those subsets, which we'll call $\\mathbf{D}_i$'s, correspond to *complete subgraphs* of $\\mathcal{H}$ and their union makes up the whole of $\\mathcal{H}$. We can refer to this set as $\\Phi=\\{\\phi_i(\\cdots)\\}_{i=1}^m$. With that, we say that the 'Gibbs Rule' for calculation probabilities is:\n",
    "\n",
    "$$\n",
    "P_M(X_1,\\cdots,X_n) = \\frac{1}{Z} \\underbrace{\\prod_{i = 1}^m \\phi_i(\\mathbf{D}_i)}_{\\text{we call this }\\tilde{P}_M(X_1,\\cdots,X_n)}\n",
    "$$\n",
    "\n",
    "where $Z$ is a normalizer - it ensures our probabilities sum to 1.\n",
    "\n",
    "To crystallize this idea, it's helpful to imagine the 'Gibbs Table', which lists unnormalized probabilities for all assignments. In the second answer [link], we pictured an example where $\\mathcal{X}=\\{C,D,I,G,S\\}$ as:\n",
    "\n",
    "![Title](GIbbsTable_labeled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got it, but what... are we doing?\n",
    "\n",
    "We're here to determine those factors given a lump of data, $\\mathcal{D}$, and an MN graph, $\\mathcal{H}$. To start, we'll assume our data is complete, meaning each observation is a joint assignment to *all* RVs of $\\mathcal{X}$. More specifically, let $\\mathbf{X}=\\mathcal{X}$ and let's write our data as: $\\mathcal{D}=\\{\\mathbf{x}^{(i)}\\}_{i=1}^w$, where no entries in these vectors are missing.\n",
    "\n",
    "It'll help, actually, to restrict our goal slightly. In Markov Networks, we run into problems with factors that give zero probabilities to some assignments. So, we'll be better off considering factors that avoid that. We can do with a function called a *feature*, which map assignments to some *real number*. If we denote these features as $f_i(\\cdot)$, then we define them as:\n",
    "\n",
    "$$\n",
    "\\phi_i(\\mathbf{D}_i) = \\exp(f_i(\\mathbf{D}_i))\n",
    "$$\n",
    "\n",
    "Think of a feature as just another way of specifying a factor, where that factor has to be positive. Now we can rewrite our Gibbs Rule:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P_M(X_1,\\cdots,X_n) & = \\frac{1}{Z} \\prod_{i = 1}^m \\exp(f_i(\\mathbf{D}_i)) \\\\\n",
    "& = \\frac{1}{Z} \\exp\\big(\\sum_{i = 1}^m f_i(\\mathbf{D}_i)\\big) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This is good, but it would be nice if we could see the parameters. Right now, they are hiding as the outputs of $f_i(\\cdot)$. Here's an idea: let's *redefine* $f_i(\\cdot)$ as an indicator function. It's 1 when $\\mathbf{D}_i$ take a certain value and 0 otherwise. Then we can say:\n",
    "\n",
    "$$\n",
    "P_M(X_1,\\cdots,X_n) = \\frac{1}{Z} \\exp\\big(\\sum_{i = 1}^m \\theta_i f_i(\\mathbf{D}_i)\\big)\n",
    "$$\n",
    "\n",
    "where $\\theta_i$ is a real valued number.\n",
    "\n",
    "At this point, you might have a reasonable complaint. That is, if we have $m$ feature function, each of which map assignments to real numbers, we can't reproduce it's output with $m$ indicator functions and *just* $m$ real valued numbers. There aren't enough degrees of freedom! Yes, I've sneakly increased $m$. The point is, given any set of features, we *could* invent another *larger* set of indicator functions and $\\theta_i$'s that produce it's same output. The confusing part here is that we are overloading on notation. The $m$, $f_i$'s and $\\mathbf{D}_i$'s all change when we make the switch to indicator world. Specifically, we now repeat a $\\mathbf{D}_i$ for every *value* in the original $Val(\\mathbf{D}_i)$. The associated $f_i(\\cdot)$ for a repeated $\\mathbf{D}_i$ is an indicator for that value. [1]\n",
    "\n",
    "So, in one sentence: our goal is to determine the $\\theta_i$'s give some data $\\mathcal{D}$, a graph $\\mathcal{H}$ and a set of indicator functions $f_i(\\cdot)$.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Likelihood Function\n",
    "\n",
    "To determine the $\\theta_i$'s, we need the *Likelihood Function*, which was explained in answer 5[link] as:\n",
    "\n",
    "\"\n",
    "To do so, we have to introduce the **likelihood function**. A likelihood function accepts parameters and returns a number that tells us how *likely* a fixed set of data is according to those parameters. The guiding principle is to pick parameters that maximize this function, i.e. the likelihood of our data. Such parameters are called our **Maximum Likelihood Estimate ('MLE').** To write this out, it's typical to say $\\boldsymbol{\\theta}$ is a vector that lists out our parameters that our likelihood function is $\\mathcal{L}(\\boldsymbol{\\theta})$. Further, the argmax of such a function is the same as the argmax of the *log* of this function, and since log-ing turns difficult multiplication into easy addition, we maximize the log likelihood, $\\log \\mathcal{L}(\\boldsymbol{\\theta})$.\n",
    "\"\n",
    "\n",
    "In the case of a MN, the parameters are those used in our specification of $P_M$, so $\\boldsymbol{\\theta}=[\\theta_1,\\cdots,\\theta_m]$. With that, our goal is to find:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta}^* = \\textrm{argmax}_\\boldsymbol{\\theta} \\log \\mathcal{L}(\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "In the case of a BN, we saw a very fortunate decomposition. That was, we could optimize pieces of $\\boldsymbol{\\theta}$ *independently*, paste them together at the end, and be assured that was the global optimum. In this general form of a MN, we do *not* have such good fortune. What this means is that we have to optimize all $\\theta_i$'s *together*, which means we're responsible for searching a volume with dimension $m$. As you can imagine, that volume might be huge. The reason for this is that damn $Z$ term, which is the sum of the $\\tilde{P}_M$ column in our Gibbs Table. It creates an iteraction between all our $\\theta_i$'s whereby the best choice of any one of them may depend on the settings of all the others. Because we'd like to call attention to this fact and that $Z$ is a function of $\\boldsymbol{\\theta}$, we'll change notation slightly as: $Z \\rightarrow Z(\\boldsymbol{\\theta}).$\n",
    "\n",
    "Despite this, we'll charge forward with this optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing $\\log \\mathcal{L}(\\boldsymbol{\\theta})$\n",
    "\n",
    "This is where the math gets nicely intuitive. Let's write out the log-likelihood with our specification of a MN. It simplify things to consider the log-likelihood *per* sample, so:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{w} \\log \\mathcal{L}(\\boldsymbol{\\theta}) & = \\frac{1}{w} \\log \\big( \\prod_{j=1}^w \\frac{1}{Z(\\boldsymbol{\\theta})} \\exp\\big(\\sum_{i = 1}^m \\theta_i f_i(\\mathbf{d}_i^{(j)})\\big) \\big) \\\\\n",
    "& = \\frac{1}{w} \\big( \\sum_{j=1}^w \\sum_{i = 1}^m \\theta_i f_i(\\mathbf{d}_i^{(j)}) \\big) - \\log Z(\\boldsymbol{\\theta}) \\\\\n",
    "& =  \\sum_{i = 1}^m \\theta_i \\mathbb{E}_\\mathcal{D}[f_i(\\mathbf{D}_i)] - \\log Z(\\boldsymbol{\\theta})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{d}_i^{(j)}$ are the $\\mathbf{D}_i$ elements from the observation $\\mathbf{x}^{(j)}$ and $\\mathbb{E}_\\mathcal{D}[f_i(\\mathbf{D}_i)]$ is the *empirical* expectation of $f_i(\\mathbf{D}_i)$. In other words, it's the number of times that indicator function produced a 1 in our data, divided by our number of observations, $w$.\n",
    "\n",
    "Now, this is the cool part. (CALC DERIVATIVE)\n",
    "\n",
    "(OLD STUFF BELOW)\n",
    "\n",
    "Since we'd like maximize this, the first step number is always calculate the derivative. To keep things short, I'll just tell you that:\n",
    "\n",
    "$$\n",
    "\\frac{1}{w} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\log \\mathcal{L}(\\boldsymbol{\\theta}) = sum_{i = 1}^m \\theta_i \\mathbb{E}_\\mathcal{D}[f_i(\\mathbf{D}_i)]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\log \\mathcal{L}(\\boldsymbol{\\theta})  & = w \\frac{1}{Z(\\boldsymbol{\\theta})} \\frac{\\partial }{\\partial \\boldsymbol{\\theta}} Z(\\boldsymbol{\\theta}) + \\\\ \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footnotes\n",
    "\n",
    "[1] Originally, I explained this mathematically, but it introduced a bunch of ugly notation for a rather small point, so I cut it out.\n",
    "\n",
    "[2] You might think we have an indicator $f_i(\\cdot)$ for every value across all subgraphs of $\\mathcal{H}$. Yes, that would be the case if we wish to reproduce the original non-indicator feature-form of the Gibbs Rule. But it doesn't *have to* be that way. We could be dealing with any indicator functions - maybe ones that highlight sets of values.\n",
    "\n",
    "### Sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap\n",
    "\n",
    "This is good, but it would be nice if we could see the parameters. Right now, they are hiding as the outputs of $f_i(\\cdot)$. Here's an idea: let's say $k_i$ is an index over all the values in $Val(\\mathbf{D}_i)$. That is, $k_i \\in {1,\\cdots,|Val(\\mathbf{D}_i)|}$ where $|Val(\\mathbf{D}_i)|$ is the number of elements in $Val(\\mathbf{D}_i)$. Then, let's say $f_{i,k_i}(\\cdot)$ is an indicator function that is 1 if the given $\\mathbf{D}_i$-value is the $k_i$-th value. In other words, $f_{i,k_i}(\\cdot)$ goes off when it gets one specific value of $\\mathbf{D}_i$. Let's also $\\theta_{i,k_i}$ is a real value associated with each of these. Then we could say:\n",
    "\n",
    "$$\n",
    "f_i(\\mathbf{D}_i) = \\sum_{k_i=1}^{|Val(\\mathbf{D}_i)|} \\theta_{i,k_i} f_{i,k_i}(\\mathbf{D}_i)\n",
    "$$\n",
    "\n",
    "Here $\\theta_{i,k_i}$ is the output of $f_i(\\cdot)$ of the $k_i$-th value in $Val(\\mathbf{D}_i)$. All we've done is rewritten it using indicators functions. This changes our Gibbs Rule to:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P_M(X_1,\\cdots,X_n) & = \\frac{1}{Z} \\prod_{i = 1}^m\\exp(-\\sum_{k_i=1}^{|Val(\\mathbf{D}_i)|} \\theta_{i,k_i} f_{i,k_i}(\\mathbf{D}_i)) \\\\\n",
    "& = \\frac{1}{Z} \\exp(-\\sum_{i = 1}^m \\sum_{k_i=1}^{|Val(\\mathbf{D}_i)|} \\theta_{i,k_i} f_{i,k_i}(\\mathbf{D}_i)) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "OK, this does what we want, but uhh...it's heavy on the notation, don't you think? Well, that double sum across indices can be thought of as a single sum across one fat index. So let's make this change:\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^m \\sum_{k_i=1}^{|Val(\\mathbf{D}_i)|} \\theta_{i,k_i} f_{i,k_i}(\\mathbf{D}_i)) \\rightarrow \\sum_{i = 1}^m \\theta_i f_i(\\mathbf{D}_i))\n",
    "$$\n",
    "\n",
    "This is indeed a change. The $i$'s and $m$'s on the right are *redefined* such that they match the left. They mean something totally different then what they did before - I'm just reusing the $i$ and $m$ notation. Also, implicitly, the $\\mathbf{D}_i$'s are now repeated a bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
