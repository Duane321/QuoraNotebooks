{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on MLPP's chap 12: Variational Inference:\n",
    "- asdas\n",
    "\n",
    "\n",
    "What needs to be mentioned?\n",
    "\n",
    "- Parameters can be viewed as hidden variables..\n",
    "- I haven't even mentioned hidden variables yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Variance Inference?\n",
    "\n",
    "(This answer is the 3rd answer in a 7 part series on Probabilistic Graphical Models)\n",
    "\n",
    "[Be aware: Readers could come directly from the FIRST question]\n",
    "\n",
    "As you may know by this point, inference is the task of using a model of a system to calculate answers regarding that system. 'Variational' inference refers to a specific technique to do so *approximately* - a necessary consession when the exact alternative is hopelessly expensive. We'll discover that it relies on recasting inference as an optimization problem, which comes with a few benefits:\n",
    "\n",
    "1. Many optimization techniques are suddenly at our disposal\n",
    "2. We have additional insight into the nature of our problem.\n",
    "3. A by-product of our calculations is very useful for model selection.\n",
    "\n",
    "But first, I'll recap all that is necessary to understand this answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A refresher\n",
    "\n",
    "In my first answer [link], we discovered why Probabilistic Graphical Models (PGMs) are useful tools for studying complex system. To recap, a complex system is a set of random variables (which we'll call $\\mathcal{X}$) with a relationship we'd like to understand. We are given some, at least partial, joint observations of $\\mathcal{X}$. We've decided that a good understanding of our system means we can answer:\n",
    "\n",
    "1. **Probability Queries**: Compute the probabilities $P(\\mathbf{Y}|\\mathbf{X}=\\mathbf{x})$. What is the distribution of the RV's of $\\mathbf{Y}$ given we have some observation of those RVs of $\\mathbf{X}$?\n",
    "2. **MAP Queries**: Determine $\\textrm{argmax}_\\mathbf{y}P(\\mathbf{Y}=\\mathbf{y}|\\mathbf{X}=\\mathbf{x})$ when given $\\mathbf{x}$. That is, determine the most likely values of random variables (RVs) given an assignment of other RVs.\n",
    "\n",
    "(Where $\\mathbf{X}$ and $\\mathbf{Y}$ are two arbitrary non-overlapping subsets of $\\mathcal{X}$ and $\\mathbf{x}$ is an observed assignment of $\\mathbf{X}$. If this notation is unfamiliar, see the 'Preamble Notes' section from the last answer).\n",
    "\n",
    "We discovered that even if we had the joint distribution of $\\mathcal{X}$ (called $P$), we could only answer these questions if we had certain simplifications on $P$. Those simplifications were **conditional independence (CI) statements**. If such statements are true for $P$ (stated as '$P$ satisfies these CI statements'), it simplifies calculations on $P$.\n",
    "\n",
    "The big innovation of PGMs is that we may *represent* sets of CI statement with a graph of nodes and edges, and therefore, represent all $P$'s which satisfy them. The two dominate types of PGMs are the Bayesian Network (BN) and the Markov Network (MN). A BN is associated with a graph with *directed* edges (a DAG) and uses the Chain Rule, along with Conditional Probability Tables ('CPTs' or 'CPDs'), to determine probabilities. A choice of CPDs makes the BN recreate the probabilities of a specific $P$. Similarly, a MN is associated with an *undirected* graph, which may represent a different class of CI statements. Instead of the Chain Rule, a MN uses functions called *factors* to calculate probabilities. I called this the 'Gibbs Rule'.\n",
    "\n",
    "The task of *inference* is to use a given PGM and it's parameters (CPDs in the case of BNs and factors in the case of MNs) to answer those queries. Without sufficient cleverness, this may be computationally infeasible.\n",
    "\n",
    "The second answer [link] isn't a prerequisite for this , but it's necessary to repeat two ideas from it.\n",
    "\n",
    "The first is that we can always recreate the probabilities produced by a BN's Chain Rule with a MN's Gibbs Rule. Essentially, we define factors that reproduce a BN's CPDs to do. This equivalence allows us to reason solely in terms of the Gibbs Rule, while assured that whatever we discover will also hold for BNs.\n",
    "\n",
    "That said, let's review a Markov Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A peak ahead\n",
    "\n",
    "(talk about parameter learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
