{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 13 - MAP Inference\n",
    "\n",
    "### Overview\n",
    "\n",
    "* MAP query aims to find the most likely assignment to all of the non-evidence variables. A marginal MAP query aims to find the most likely assignment to a subset of the variables, marginalizing out the rest.\n",
    "* (Skipping discussion of complexity and hardness)\n",
    "* **Overview of Solution Methods**: \n",
    "    * It's useful to think of the joint distribution as a product of factors. So we consider the distribution $P_\\Phi(\\mathcal{X})$ with the set of factors $\\Phi$. The unnormalized version is $\\tilde{P}_\\Phi(\\mathcal{X})$\n",
    "    * We want to calculate:\n",
    "$$\n",
    "\\xi^{map} = \\textrm{argmax}_\\xi P_\\Phi(\\mathcal{X}=\\xi) = \\textrm{argmax}_\\xi \\tilde{P}_\\Phi(\\mathcal{X}=\\xi)\n",
    "$$\n",
    "    * If we know the MAP assignment, it's easy to determine the unnormalized probability. However it's *not* easy to determine the actual probability. We would need to determine the sum of the whole gibbs table - the $Z$.\n",
    "    * Since we are referring to a product of factors, this is often called a 'max-product' inference task. Though we typically maximize $\\log \\tilde{P}_\\Phi$, which is a sum of negative 'energies'. So it's sometimes called 'max-sum'. Sometimes we negate this and minimize.\n",
    "    * There are advantages in the log space:\n",
    "        * numerical overflow is better handled\n",
    "        * the problem is now *linear*\n",
    "    * This book will use the 'max-product' form of the problem, though everything can be easily converted to max-sum or min-sum.\n",
    "    * This problem is clearly an optimization problem.\n",
    "    * A max-marginal of a function f relative to a set of variables $\\mathbf{Y}$ is:\n",
    "    $$\n",
    "    MaxMarg_f(\\mathbf{y}) = \\textrm{max}_{\\xi \\langle \\mathbf{Y} \\rangle = \\mathbf{y}} f(\\xi)\n",
    "    $$\n",
    "    $\\xi \\langle \\mathbf{Y} \\rangle$ means assignment of $\\xi$ for the RVs of $\\mathbf{Y}$. So the max-marginal is the max *value* of $f(\\cdot)$ over all assignments $\\xi$ where it has a subset of values in agreement with $\\mathbf{y}$.\n",
    "    * 'A large class of MAP algorithms proceed by first computing an exact or approximate set of max-marginals for all of the variables in X , and then attempting to extract an exact or approximate MAP assignment from these max-marginals.' - Notice it's individual RVs!\n",
    "    * 'As we show, the computation of (approximate) max-marginals allows us to solve a global optimization problem as a set of local optimization problems for individual variables. This task, known as decoding, is to decoding max-marginals construct a joint assignment that locally optimizes each of the beliefs.'\n",
    "    * When max-marginals are unambiguous (there is a unique $x_i$ to maximize the max-marginal of $X_i$), then identifying locally optimizing assignment is easy. (What does locally optimized here mean? Isn't the next step the global step?)\n",
    "    * The *marginal* MAP query is much harder:\n",
    "    $$\n",
    "    \\mathbf{y}^{m-map} = \\textrm{arg max}_\\mathbf{y}P_\\Phi(\\mathbf{y}) = \\textrm{arg max}_\\mathbf{y} \\sum_\\mathbf{W}\\tilde{P}_\\Phi(\\mathbf{y},\\mathbf{W})\n",
    "    $$\n",
    "    because it involves both sums and maxes. The only effective approximate methods are a heuristic search over $\\mathbf{y}$ and then using sum-product inference over $\\mathbf{W}$ for each $\\mathbf{y}$ (Slow!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Elimination\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
