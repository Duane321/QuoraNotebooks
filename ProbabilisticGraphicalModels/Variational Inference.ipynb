{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on MLPP's chap 12: Variational Inference:\n",
    "- \n",
    "\n",
    "\n",
    "What needs to be mentioned?\n",
    "\n",
    "- Parameters can be viewed as hidden variables..\n",
    "- I haven't even mentioned hidden variables yet!\n",
    "- How does conditioning on $\\mathbf{x}$ relate to conditioning on $D$ (think of many Gibbs table and you average their answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Variance Inference?\n",
    "\n",
    "(This answer is the 3rd answer in a 7 part series on Probabilistic Graphical Models)\n",
    "\n",
    "[Be aware: Readers could come directly from the FIRST question]\n",
    "\n",
    "As you may know by this point, inference is the task of using a model of a system to calculate answers regarding that system. 'Variational' inference refers to a specific technique to do so *approximately* - a necessary consession when the exact alternative is hopelessly expensive. We'll discover that it relies on recasting inference as an optimization problem, which comes with a few benefits:\n",
    "\n",
    "1. Many optimization techniques are suddenly at our disposal\n",
    "2. We have additional insight into the nature of our problem.\n",
    "3. A by-product of our calculations is very useful for model selection.\n",
    "\n",
    "But first, I'll recap all that is necessary to understand this answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A refresher\n",
    "\n",
    "In the first answer [link], we discovered why Probabilistic Graphical Models (PGMs) are useful tools for studying complex system. We'd defined a complex system as a set of $n$ random variables (which we'll call $\\mathcal{X}$, so $\\mathcal{X}=\\{X_1,\\cdots,X_n\\}$ for example) with a relationship we'd like to understand. We are given some, at least partial, joint observations of $\\mathcal{X}$. Performing *inference* means using a given PGM (complete with parameters) to answer:\n",
    "\n",
    "1. **Probability Queries**: Compute the probabilities $P(\\mathbf{Y}|\\mathbf{X}=\\mathbf{x})$. What is the distribution of the RV's of $\\mathbf{Y}$ given we have some observation of the RVs of $\\mathbf{X}$?\n",
    "2. **MAP Queries**: Determine $\\textrm{argmax}_\\mathbf{y}P(\\mathbf{Y}=\\mathbf{y}|\\mathbf{X}=\\mathbf{x})$ when given $\\mathbf{x}$. That is, determine the most likely values of random variables (RVs) given an assignment of other RVs.\n",
    "\n",
    "(Where $\\mathbf{X}$ and $\\mathbf{Y}$ are two arbitrary non-overlapping subsets of $\\mathcal{X}$ and $\\mathbf{x}$ is an observed assignment of $\\mathbf{X}$. If this notation is unfamiliar, see the 'Preamble Notes' section from the last answer).\n",
    "\n",
    "We discovered that even if we had the joint distribution of $\\mathcal{X}$ (called $P$), we could only answer these questions if we had certain simplifications on $P$. Those simplifications were **conditional independence (CI) statements**. If such statements are true for $P$ (stated as '$P$ satisfies these CI statements'), it simplifies calculations on $P$.\n",
    "\n",
    "The big innovation of PGMs is that we may *represent* sets of CI statement with a graph of nodes and edges, and therefore, represent all $P$'s which satisfy them. The two dominate types of PGMs are the Bayesian Network (BN) and the Markov Network (MN). A BN is associated with a graph with *directed* edges (a DAG) and uses the Chain Rule, along with Conditional Probability Tables ('CPTs' or 'CPDs'), to determine probabilities. A choice of CPDs makes the BN recreate the probabilities of a specific $P$. Similarly, a MN is associated with an *undirected* graph, which may represent a different class of CI statements. Instead of the Chain Rule, a MN uses functions called *factors* to calculate probabilities. I called this the 'Gibbs Rule'.\n",
    "\n",
    "Since it'll be important, let's review the Gibbs Rule in more detail. Let's say we have an MN graph (call it $\\mathcal{H}$) with nodes for each RV of $\\mathcal{X}$. The set of nodes for each complete subgraph are given by $\\{\\mathbf{D}_i\\}_{i=1}^m$ and for each of these, we have an associated factor, the set of which can be represented as $\\Phi=\\{\\phi_i(\\cdots)\\}_{i=1}^m$. A factor is just a function that maps from some assignment to a positive (nonnegative?) number. With that, the Gibbs Rule tells us to calculate probabilities as:\n",
    "\n",
    "$$\n",
    "P(X_1,\\cdots,X_n) = \\frac{1}{Z} \\prod_{\\phi_i\\in \\Phi} \\phi_i(\\mathbf{D}_i)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "Z = \\sum_{\\mathbf{x}\\in Val(\\mathcal{X})} \\prod_{\\phi_i\\in \\Phi} \\phi_i(\\mathbf{D}_i)\n",
    "$$\n",
    "\n",
    "For a given assignment, we say that $\\prod_{\\phi_i\\in \\Phi} \\phi_i(\\mathbf{D}_i)$ is the 'unnormalized probability', often abbreviated as $\\tilde{P}(\\cdots)$. To crystallize this idea, it's helpful to imagine the 'Gibbs Table', which lists unnormalized probabilities for all assignments. In the second answer [link], we pictured an example where $\\mathcal{X}=\\{C,D,I,G,S\\}$ as:\n",
    "\n",
    "![Title](GIbbsTable_labeled.png)\n",
    "\n",
    "Speaking of the the second answer [link], it's not a prerequisite for this, but it's necessary to steal two other ideas from it.\n",
    "\n",
    "The first is that we can always recreate the probabilities produced by a BN's Chain Rule with an another invented MN and its Gibbs Rule. Essentially, we define factors that reproduce a BN's CPDs to do. This equivalence allows us to reason solely in terms of the Gibbs Rule, while assured that whatever we discover will also hold for BNs.\n",
    "\n",
    "The second is that inference ultimately reduces to two tasks. For performing probability queries, it reduces to summing up unnormalized probabilities of the Gibbs Table when we filter to rows that have some assignment of some subsets of $\\mathcal{X}$. For MAP queries, it comes down to finding max unnormalized probabilities after this filtering[1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The big problem.\n",
    "\n",
    "The issue is that the Gibbs Table may have exponentially many rows (assignments) and we can't sum effeciently across them. Exact inference algorithms help, but their 'exact' constraint puts significant limits on their speed.\n",
    "\n",
    "So we need to be clever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The big idea.\n",
    "\n",
    "The general idea behind Variational Inference is to consider a space of 'simple' probability distributions and pick one that closely approximates $P$. The 'simple' constraint on these probability distributions is there to ensure we can perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A peak ahead\n",
    "\n",
    "(talk about parameter learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footnotes\n",
    "\n",
    "[1] This is only the case when $\\mathbf{X}$ and $\\mathbf{Y}$ make up the whole of $\\mathcal{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
